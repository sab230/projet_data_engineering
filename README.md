# üå¶Ô∏è M√©t√©oFlow

[![Status Build](https://img.shields.io/badge/Pipeline-Stable-brightgreen)](http://localhost:8080)
[![Technologies](https://img.shields.io/badge/Stack-Airflow%20%7C%20Snowflake%20%7C%20dbt-blue)]()
[![Licence](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE.md)

**M√©t√©oFlow** est un pipeline complet de *Data Engineering* con√ßu pour collecter, transformer, stocker et visualiser des donn√©es m√©t√©orologiques **en temps r√©el**. Il s‚Äôappuie sur une architecture moderne utilisant **Airflow** pour l'orchestration et **Snowflake** comme Data Warehouse.

---

## üß≠ Table des Mati√®res

* [üéØ Objectifs du Projet](#-objectifs-du-projet)
* [üèóÔ∏è Architecture Globale](#Ô∏è-architecture-globale)
* [üöÄ Pour Commencer](#-pour-commencer)
* [‚öôÔ∏è Installation (Docker)](#Ô∏è-installation-docker)
* [‚ñ∂Ô∏è D√©marrage](#Ô∏è-d√©marrage)
* [üõ†Ô∏è Fabriqu√© avec](#Ô∏è-fabriqu√©-avec)
* [‚úíÔ∏è Auteurs & Contact](#Ô∏è-auteurs--contact)
* [‚öñÔ∏è Licence](#Ô∏è-licence)

---

## üéØ Objectifs du Projet

Le pipeline a √©t√© con√ßu pour :

* Collecter automatiquement des donn√©es m√©t√©o depuis l'***API OpenWeather***.
* Orchestrer l'ensemble du workflow **ETL** avec **Airflow**.
* Stocker les donn√©es historis√©es dans **Snowflake**.
* Mod√©liser les donn√©es analytiques avec **dbt**.
* Exposer les m√©triques en *temps r√©el* dans un dashboard **Grafana**.

---

## üèóÔ∏è Architecture Globale

Le flux de donn√©es est g√©r√© par un DAG Airflow qui pilote les transformations Python et dbt :

> OpenWeather API ‚Üí **Airflow** ‚Üí ETL Python ‚Üí **Snowflake** (RAW ‚Üí STAGING ‚Üí ANALYTICS) ‚Üí **PostgreSQL** ‚Üí **Grafana**

### Sch√©ma Logique

| Composant | R√¥le |
| :--- | :--- |
| **Airflow** | **Orchestration** des t√¢ches (Extract, Transform, Load, Model). |
| **Snowflake** | **Data Warehouse** Cloud central. |
| **dbt** | Mod√©lisation des donn√©es SQL et cr√©ation des tables BI. |
| **Grafana** | Visualisation et Dashboards m√©tier. |

---

## üöÄ Pour Commencer

Ce projet n√©cessite **Docker** et **Docker Compose** pour initialiser l'infrastructure compl√®te. Vous aurez √©galement besoin de vos credentials de services cloud.

### Pr√©-requis

* **Docker** et **Docker Compose** (v√©rifiez l'installation avec `docker --version`).
* Une cl√© d'API valide pour **OpenWeatherMap**.
* Des identifiants de connexion **Snowflake** (compte, utilisateur, mot de passe).

### Gestion des Credentials (IMPORTANT)

Vous devez cr√©er un fichier nomm√© **`.env`** dans le dossier `/airflow` pour y placer les secrets. Ce fichier est ignor√© par Git.

```bash
# Exemple de contenu pour .env
OPENWEATHER_API_KEY=votre_cle_api_secrete_ici

SNOWFLAKE_ACCOUNT=votre_compte
SNOWFLAKE_USER=votre_user
SNOWFLAKE_PASSWORD=votre_mot_de_passe
# ... autres variables DB et POSTGRES
